{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "imdb_classification_lr_word2vec.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vyWYHMxGrED"
      },
      "source": [
        "# IMDB 리뷰 감성 분류 : Word2Vec 활용 로지스틱 회귀 모델\n",
        "- 데이터 전처리 : imdb_preprocessing.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yd_gvGS1M-On"
      },
      "source": [
        "## 라이브러리 임포트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7iGX9wybeCi"
      },
      "source": [
        "import logging\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from gensim.models import word2vec\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',level=logging.INFO)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0lOU2YTgkzW",
        "outputId": "dea145ed-4055-4454-d0e8-4481cabae28f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7soyELrgbd_l"
      },
      "source": [
        "DATA_PATH = '/content/drive/MyDrive/nlpdata/imdb/'\n",
        "TRAIN_CLEAN_DATA = 'train_clean.csv'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ms0BI2dqbd8t"
      },
      "source": [
        "train_data = pd.read_csv(DATA_PATH + TRAIN_CLEAN_DATA)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1-56X5ubd5u"
      },
      "source": [
        "reviews = list(train_data['review'])\n",
        "sentiments = list(train_data['sentiment'])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQl1O_G5J8_9"
      },
      "source": [
        "## word2vev을 사용하기 위해 입력값을 단어로 구분된 리스트로 만듬 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBjjnHM9bd2i"
      },
      "source": [
        "sentences = []\n",
        "for review in reviews:\n",
        "    sentences.append(review.split())"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6icAiM2KKL3V"
      },
      "source": [
        "## word2vec 학습 및 모델 저장\n",
        "- gensim 라이브러리가 설치 안 되어 있으면 설치\n",
        "- `!pip install gensim`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCwLmSqHKLgV"
      },
      "source": [
        "num_features = 300      # 단어 임베딩 벡터 차원수\n",
        "min_word_count = 40     # 적은 빈도의 수의 단어는 학습하지 않음\n",
        "num_workers = 4         # 모델 학습 프로세스 개수\n",
        "context = 10            # 컨텍스트 윈도 크기\n",
        "downsampling = 1e-3     # 다운 샘플링 비율(보통 0.001)\n",
        "\n",
        "model = word2vec.Word2Vec(sentences, workers=num_workers,\n",
        "                          size=num_features, min_count=min_word_count,\n",
        "                          window = context, sample=downsampling)\n",
        "\n",
        "model_name = \"300features_40minwords_10context\"\n",
        "model.save(DATA_PATH +model_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NqpkkV6KSii"
      },
      "source": [
        "### 분류 모델 학습을 위해 입력값을 같은 형태로 만듬\n",
        "각 리뷰에 있는 전체 단어의 평균값을 계산하는 함수\n",
        "- words : 단어의 모음인 하나의 리뷰 데이터\n",
        "- model : 학습된 word2vec 모델\n",
        "- num_features : 임베딩 벡터 차원수\n",
        "index2word_set 셋으로 문장의 단어가 모델 단어사전에 속하는지 확인\n",
        "\n",
        "1. model.wv.index2word로 set 객체 생성\n",
        "2. 반복문으로 임베딩된 벡터가 있는 단어 벡터의 합을 구함\n",
        "3. 단어의 전체 개수로 나누어 평균 벡터의 값 계산"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggQfsHZCcPae"
      },
      "source": [
        "def get_features(words, model, num_features):\n",
        "    feature_vector = np.zeros((num_features),dtype=np.float32)\n",
        "\n",
        "    num_words = 0\n",
        "    index2word_set = set(model.wv.index2word)\n",
        "\n",
        "    for w in words:\n",
        "        if w in index2word_set:\n",
        "            num_words += 1\n",
        "            feature_vector = np.add(feature_vector, model[w])\n",
        "\n",
        "    feature_vector = np.divide(feature_vector, num_words)\n",
        "    return feature_vector"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sq9y-1iFKWAj"
      },
      "source": [
        "### 전체 리뷰에 대해 각 리뷰의 평균 벡터를 구하는 함수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_0evumXcPXR"
      },
      "source": [
        "def get_dataset(reviews, model, num_features):\n",
        "    dataset = list()\n",
        "\n",
        "    for s in reviews:\n",
        "        dataset.append(get_features(s, model, num_features))\n",
        "\n",
        "    reviewFeatureVecs = np.stack(dataset)\n",
        "    \n",
        "    return reviewFeatureVecs"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzRHKIQWcPUJ"
      },
      "source": [
        "test_data_vecs = get_dataset(sentences, model, num_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0MPTgZfKZnz"
      },
      "source": [
        "## 학습과 검증 데이터셋 분리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4GBo2SicPRH"
      },
      "source": [
        "X = test_data_vecs\n",
        "y = np.array(sentiments)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EImGxj4cKeKQ"
      },
      "source": [
        "## 로지스틱 회귀 모델 선언 및 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZQQmz4JcPN3"
      },
      "source": [
        "lr = LogisticRegression(class_weight='balanced')\n",
        "lr.fit(X_train, y_train)\n",
        "print(f\"Accuracy: {lr.score(X_test, y_test):.2f}\") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ys5AwMRncvEw"
      },
      "source": [
        "TEST_CLEAN_DATA = 'test_clean.csv'\n",
        "test_data = pd.read_csv(DATA_PATH + TEST_CLEAN_DATA)\n",
        "test_review = list(test_data['review'])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-DV14xwcu-n"
      },
      "source": [
        "test_sentences = list()\n",
        "for review in test_review:\n",
        "    test_sentences.append(review.split())"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJui84FTdO2b"
      },
      "source": [
        "test_data_vecs = get_dataset(test_sentences, model, num_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDLcJLgAdOy8"
      },
      "source": [
        "ids = list(test_data['id'])\n",
        "test_predicted = lr.predict(test_data_vecs)\n",
        "\n",
        "answer_dataset = pd.DataFrame({'id': ids, 'sentiment': test_predicted})\n",
        "answer_dataset.to_csv(DATA_PATH + 'answer_lr_w2v.csv', index=False, quoting=3)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuv8pe3ANT6a"
      },
      "source": [
        "## kgggle에 결과 제출 및 스코어 확인\n",
        "- https://www.kaggle.com/c/word2vec-nlp-tutorial"
      ]
    }
  ]
}